{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U transformers\n",
        "!pip install -U peft\n",
        "!pip install -U accelerate\n",
        "!pip install -U datasets\n",
        "!pip install -U trl"
      ],
      "metadata": {
        "id": "DsO7khSPR9Cy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import SFTTrainer, SFTConfig"
      ],
      "metadata": {
        "id": "rLlieIfRdDdB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# 1. Load the reliable MedAlpaca dataset\n",
        "dataset = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\", split=\"train\")\n",
        "\n",
        "# 2. Define the formatting function\n",
        "def format_medical_prompts(example):\n",
        "    # This dataset uses 'input' for the question and 'output' for the answer\n",
        "    # We format it into the Mistral instruction format: <s>[INST] Q [/INST] A </s>\n",
        "    text = f\"<s>[INST] {example['input']} [/INST] {example['output']} </s>\"\n",
        "    return {\"text\": text}\n",
        "\n",
        "# 3. Apply the format\n",
        "dataset = dataset.map(format_medical_prompts)\n",
        "\n",
        "# 4. Check a sample (It should look perfect now)\n",
        "print(\"Sample Input to Model:\")\n",
        "print(dataset[0]['text'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "662d21f1fd2849458c96555243dd3d8f",
            "a8e5d70543674617a2a228f99b63f154",
            "97b821c1468745349133fcdc8b874f34",
            "d5d0c8bb0c8c40cd967c0f7527ce6fcf",
            "a104ba005dbe47f4a846588c4823b02d",
            "a6ce4442adb343abbec4e6b363e57749",
            "c6ef17d416ef4298afd2d164876a2cd7",
            "12c5b2b3646c41788d2e1c834b9ce233",
            "9c6615e3d7344675830b64d8c5b16e7f",
            "ec0bd76f9cf2469e8b9f7598c3d3a67b",
            "5fc7b85dd2da4dcabaef8e6229442d9b",
            "75849020572c4028b014b42619382584",
            "6a82b9e61c5d43479e986c84b2285934",
            "f0bc5de52308477eaf6a095416012154",
            "19b240ec593b42399e8874124eeb99db",
            "b1a8dd9954164c818dffb8fd75dc6fe2",
            "4d9a9d81955a47b9983da25b022ccd86",
            "8ebd958dd0ac4d6ea3d02774f57e31c7",
            "f65cd1cc1a424614afc0f25e7c539553",
            "835ace06aaa848eca7cff622682ffa59",
            "f41cf73178fc43e2b62680821890b4e6",
            "262ef58e8d024465a0291363e30ab1b5",
            "4af295cd2ff541f495e2020ae09a5238",
            "87ae77c367c74e08b0644601df4e6536",
            "f0304fb8e8e648b2b07ed8305146dfeb",
            "a53a0d64c4a9439e83a96690d4bbcba7",
            "a5500d68ce78400f9665c0cded1c0d0f",
            "ab7ae72b24a04c8e9cff54ee21e9e9ed",
            "c7b11da4999049dc9dcddf1ffbe6b70f",
            "a97f9273a0eb4b4b8a79cbead79a1d88",
            "711224afed804219bf4800eb00cde2c8",
            "2ca049329b8948fdb3a15dac27549729",
            "cf5e558c8cd645f0a5dbc17345ca45a8",
            "e69ef5c579c046c48b016da574529983",
            "b5a172e699f244afa9ef7cc77bb3a387",
            "641542029abc485b989c537ff9b2f5ef",
            "41350997190b4ee9a4c607955a344e1a",
            "23ad25bf57374100bd13f1a6eed5aa4d",
            "f6d431eb4bd1446eb45d80d3be9ee33f",
            "76495d8ff1c0421c8e264e91d3a9ad44",
            "4a591d5e45f54373a9a0cff5b93eeae3",
            "8f2c03f7db6e4857925c55e7cff7ab00",
            "14727c15a43e48b9bf0a978734d495c2",
            "fedcdd0c23974c3991ad999ef7744e54"
          ]
        },
        "id": "zkn8EllbYzqe",
        "outputId": "6ca707bc-2026-4b74-ab86-5c6dc32885e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "662d21f1fd2849458c96555243dd3d8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "medical_meadow_wikidoc_medical_flashcard(…):   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75849020572c4028b014b42619382584"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/33955 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4af295cd2ff541f495e2020ae09a5238"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/33955 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e69ef5c579c046c48b016da574529983"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input to Model:\n",
            "<s>[INST] What is the relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels? [/INST] Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels. </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "c96cb945f14c4e42adcbc6aa3a1c6c5c",
            "8b0eb471601e450192ea76fadf117535",
            "91853c3ca098476f95cbfc3eb521f897",
            "b4a42d793b7a4551be99ea5d756ce573",
            "5873e0e01539479dafd3eb500c504aec",
            "092f38b7ac1241f092e6e3f1120ff3c0",
            "fee0f3d9a69f41b896687df19fd0ca07",
            "a940d99fd5e142e5935c894fbef78bf1",
            "fe05c53a5f254e45a8d2d667318f878b",
            "3b549f3e1f644045a6d3e5d95c11cdfb",
            "9532c2517410430b91b35be9fd99a65a",
            "a36b9edc814b4b359445a36f8b66650c",
            "312d5424c2274a1eb79b7ef71a62d8a5",
            "2eff5d43007e435f8eb3882af56764f8",
            "3dde20b0183146e6ad6f68003652f536",
            "99597416f8d9400b9c36f80aea696c19",
            "b76e3242390b45318fccf8b15ef55a6b",
            "5db323de6853466fa2a71304c5f367e2",
            "c9dd0085926f4d28935e2d3722cfd493",
            "47b6e61ec0b84acdbfcadf81b3c3245c",
            "c2e50cd863624b9899c43e64a13aa0db",
            "beef2702334e4877a97f3589cc2414b7",
            "af31fccd410d4390af84281bb83a19b7",
            "ccb35b82c0844ce8b4956ba47431e1df",
            "2eac85c6d55c4ffebd4700587a118219",
            "e9dd69f4b79045599b815f635a59d415",
            "5e9a6d8a2124441d8e6d425833ddf79d",
            "22af37cbd919424fbbad3fa54d4382bd",
            "8e19039e08af4feeab8189363a591e82",
            "77d3380adac84da49047c87df9797850",
            "34968dcc4a264c5e855c3ac4286a3c0e",
            "967261afd05140018d6f18fc55859bf8",
            "8cd0fbcaf6a445968f718d1f89669c26",
            "2a352bd5e8f84814a5d5315c0f4d2072",
            "3aa1f1ca17554675aa033ca94fedda12",
            "0b5191fab61b450497725834c116b413",
            "4d9a870f675e48929837f6e0257eab70",
            "a74092b9f1c14702a2d83ca4b7f761fb",
            "34628bca661c438cbc2996b7a273d7a7",
            "2499643c800f430ba0be12f5b4826762",
            "8cfbc7105ec94c43a2f6af68b96e3d6b",
            "cff5024a61dd4f6d9e975e7eeb3a9f8d",
            "eac7b8a5cf0d4415a96a3b8109acf934",
            "881b6a4192ca4945b46d975b79da1e26",
            "7ac3a11959d44caba832c721defd5a3d",
            "8e3119a5aa11473bb808e64c1944320f",
            "09b9b99c9bd94fa3840b03355784ab73",
            "0c65126266374d63a51bbcff4e5af7b0",
            "fd89d3f510204393ab2417d9ea2fbac9",
            "74ccaf71c9364565a15e628524041bfe",
            "261900cc427246ebb54ef7d8dfa95ff7",
            "eb4825cf72824cd7b72a0f02788595aa",
            "0c8bbff746a64ca29df502164e0e128a",
            "b27cee5dbcec4bfca32f5eb8a7d7f6d9",
            "773380769f284b9ca5a661c5319dead5",
            "8973a4dac6f549e2bdff2f00380547a6",
            "1d15b104808a4cb5a4b697dd9f116350",
            "91ac14081de14b17a85509a696e0fe73",
            "fc0cbdb1ad89452f870678daefc73793",
            "7ce4e8df24454708805cf8a729489c24",
            "7d676cedc8804039b6597aa042166d15",
            "e4e7ed710040453da9d275717e7b912a",
            "bf97e27ad4eb40109f6584691dc91991",
            "cce0535f21be49ef950a41f3b9822a2b",
            "6803ce6c5d2b42cfb6d1121837c4d571",
            "b393a34d24b6401698c60800de950c33",
            "5fe279847ed2432d894c6692762f46a3",
            "d0706ee8ea58433da63cc94930ed37c4",
            "8b0334fb8a21407fb01409f50b93895c",
            "1030ae6cabfc456e880a8702143391dd",
            "7b5ae19f31d34279854d49f950370572",
            "af30921e30724e84bbbaf082d0a8da3e",
            "a7ac4b85e5ac468cb0099232e4ffbd02",
            "c24a9e6f47ee40bda47eddfb274ce10c",
            "71d996e952de436ba3fa9e2ac3928596",
            "2659961b39974c06af98ffc03a20b562",
            "e0a5d32f70ac4f638dcf6ec39dc7feb1",
            "e2443d4aa5d044b3a549a37e830e4055",
            "15f3cf0cf8cd435abe4ab1eebe3f8542",
            "63dc2468fc714c79b30a7037628503a8",
            "495c539a45a947acbf1dc5d7e6831cf1",
            "97ee7561bcab4f03a442f7d97aa5d685",
            "ac06389c9c0540a499ad298adba44e06",
            "ec9a0fdab1704bb6b6d0eb8eda9ad73d",
            "32c01434f5404e139f0479cf1b18a501",
            "4606436f80f74a39a46f2e357d1c1d73",
            "799949b1c0784bf1a0903c2126fd5cd5",
            "489c65b4d3e847dea5ac73ddf3d26d40",
            "d941ecdd77f44cf580191fa32779fd7c",
            "bef3f7554b0644d8b506881c45b31c3e",
            "ea12d7e0b8fb430bb6ebf8033c140836",
            "20a71fffa54949bcb95f0b7baf73ade7",
            "00a90870040f4f6d960288d8b7629709",
            "99be936213e14f2fb602e82f228c10fd",
            "a58dedd3314f42cfb7024cee6157c148",
            "5d6d4e29970247c6a45870502f5e22a1",
            "d88a5786c09745faa2c8025ad3b8ad1b",
            "75ba3789b59a48828cce0e24b9387590",
            "66c1bbb14b234d6dbef16bd503e3a1d6",
            "c7023ffef79e4b96a1b2d288161f933c",
            "b3bc8cc80bf64cd69a0aca6a220c8ffb",
            "9658d44a2fac4b12a1a76fd621f85c05",
            "3d54925682d943708a7f936efe11c3b0",
            "35706fe4a2374cefbcb5e01728af1a21",
            "2f11cef0a0b242cb823db4512e034cef",
            "420837701b114590b655e5264c2b0425",
            "8d0aef5239944ba0b20db1654a0a2f0f",
            "690dd6c5eb1944258429dd4e476bc2eb",
            "59f7212a9c2144af9184fb48954bfa0c",
            "57e3d79d01714ba29ca347d5752ac7f0",
            "9026b91777ca4c76a3e5fe7d9b02476d",
            "52fd952f784345298f5f0fb12921c322",
            "7044dc7a1e9843db8b33b9176d211a7f",
            "59f48438b73b454f83de420ab4aefd99",
            "4b2e1f0d49ec49a2b0f68d1cb3f8712d",
            "28ac4a4966714bdba72f73b54d3138b0",
            "ce88f1bbdbe84818bc78b47a88061a6e",
            "f525a3e7e8524d7fb640b1f1143ce034",
            "c478f4d8ccb14db29fe8b10ebb381706",
            "93bebefd99124612b8acb2f133c278d6",
            "4db789ccd58f4393851a2e2f2669187f"
          ]
        },
        "id": "nZhnLkT8U2-l",
        "outputId": "faf8976b-4f37-477b-ea87-3e7a126e742f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c96cb945f14c4e42adcbc6aa3a1c6c5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a36b9edc814b4b359445a36f8b66650c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af31fccd410d4390af84281bb83a19b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a352bd5e8f84814a5d5315c0f4d2072"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ac3a11959d44caba832c721defd5a3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8973a4dac6f549e2bdff2f00380547a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fe279847ed2432d894c6692762f46a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2443d4aa5d044b3a549a37e830e4055"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d941ecdd77f44cf580191fa32779fd7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7023ffef79e4b96a1b2d288161f933c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9026b91777ca4c76a3e5fe7d9b02476d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Setup LoRA ---\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# --- 4. Training Arguments ---\n",
        "training_arguments = SFTConfig(\n",
        "    output_dir=\"./medalpaca_results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=25,\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=60,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "\n",
        "    # New Config Location for these arguments\n",
        "    dataset_text_field=\"text\",\n",
        "    max_length=512,\n",
        "    packing=False\n",
        ")\n",
        "\n",
        "# --- 5. Train ---\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    processing_class=tokenizer, # <--- FIXED: Renamed from 'tokenizer' to 'processing_class'\n",
        "    args=training_arguments,\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846,
          "referenced_widgets": [
            "dbda85d098234fac99c625b961d3f00e",
            "1086109127f345058bead8afc906b44b",
            "070d77b606bc44e9a97b96df467d6c20",
            "551a5f1b943648ec8920ee4e066e222e",
            "728d45e0206d44578333b52c3d395ab7",
            "ded1a50e015b4f97aabf15c5b120811f",
            "7d384d0c952a4f4d8707858f50a4c3db",
            "a17f2867c62c46a984b08de569ba7ad8",
            "5c278cd864b04beba4e62973c433c8ab",
            "ccfcfc3dc93d4c28b5392476f1cf7a3c",
            "19e7e1037cbc4e6d8a093dd01980ef02",
            "2e13b72784964e5b857fdf39e813db67",
            "e82c28c013ec4751ad29116f26c26a6c",
            "490c725f76144aefbaf76e2342ee70bc",
            "6fcd7f07420f4fbc9f6d4d5045579883",
            "2d85aab6420e43ec9d9de7ffa45666dc",
            "2d51fda7767f42b594d133453a654a13",
            "2ce4dd09de9c433e98960958c0a420d0",
            "73432115aed64c2f9deae595a610ec1d",
            "a4efae11459c4593a1c8c7a07c5916f1",
            "08fda947cdd04b579d7abacd74f8cafc",
            "f36f1a441e9f4f32ae19743fe1265f01",
            "80ab543e02ce4d028e8414c12c6dac93",
            "2f1928a73dc6453dab4ce91c0ad0f047",
            "bb442a1b39cb441ab91ddfea029b6a54",
            "2ea9d6d3e5c54345b845fcfbba543709",
            "5548dbef883543bf804a64b746a31e8e",
            "ab2be72977a34c8cb4975afe37305d3d",
            "66bd13f8e1b3466f88c028ce63f2ff3b",
            "7b8f70c616d74c3e9e249545a9d19a46",
            "c89ebbc7571f4364aa638d4c73b1dc98",
            "633495e8f5244f5a93999bccb7d7f074",
            "e9dc6c46fbd049b684959548f9d8f261"
          ]
        },
        "id": "Cx1ECTnLY5k9",
        "outputId": "53746c8b-1eac-4176-8a14-ad88c0d08937"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:397: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to train dataset:   0%|          | 0/33955 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbda85d098234fac99c625b961d3f00e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/33955 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e13b72784964e5b857fdf39e813db67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/33955 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80ab543e02ce4d028e8414c12c6dac93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://wandb.ai/authorize?signup=true&ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mae22b031\u001b[0m (\u001b[33mae22b031-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251219_122700-vttp8yo2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ae22b031-indian-institute-of-technology-madras/huggingface/runs/vttp8yo2' target=\"_blank\">vivid-dust-1</a></strong> to <a href='https://wandb.ai/ae22b031-indian-institute-of-technology-madras/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ae22b031-indian-institute-of-technology-madras/huggingface' target=\"_blank\">https://wandb.ai/ae22b031-indian-institute-of-technology-madras/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ae22b031-indian-institute-of-technology-madras/huggingface/runs/vttp8yo2' target=\"_blank\">https://wandb.ai/ae22b031-indian-institute-of-technology-madras/huggingface/runs/vttp8yo2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 02:50, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.938600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.946100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.278100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.393300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.947600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.894900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=60, training_loss=1.2331038157145182, metrics={'train_runtime': 480.9577, 'train_samples_per_second': 0.499, 'train_steps_per_second': 0.125, 'total_flos': 1469319846887424.0, 'train_loss': 1.2331038157145182, 'epoch': 0.007067970314524679})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Force the model out of training mode\n",
        "model.config.use_cache = True\n",
        "model.eval()  # Switch to Evaluation Mode\n",
        "\n",
        "# 2. Try Generating Again with stricter settings\n",
        "prompt = \"What is the treatment for acute bronchitis?\"\n",
        "inputs = tokenizer(f\"<s>[INST] {prompt} [/INST]\", return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=200,\n",
        "    do_sample=True,\n",
        "    temperature=0.1, # LOW temperature makes it more factual/robotic\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.2 # Stops it from saying \"A A A A\"\n",
        ")\n",
        "\n",
        "# 3. Print result\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw0QzMr1lyP2",
        "outputId": "2c832298-21e8-420e-9ae9-5baa0ec78788"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] What is the treatment for acute bronchitis? [/INST] Acute bronchitis can be treated with antibiotics, cough suppressants, and over-the-counter medications to relieve symptoms such as fever, sore throat, and body aches. In some cases, patients may also benefit from inhaled corticosteroids or other anti-inflammatory drugs that help reduce inflammation in the airways. It's important to note that most cases of acute bronchitis resolve on their own without any specific treatment within two weeks; however, if symptoms persist beyond this timeframe or worsen significantly, it may indicate an underlying condition requiring further evaluation by a healthcare provider. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the adapters\n",
        "new_model_name = \"Mistral-7B-Medical-Finetune\"\n",
        "save_path = f\"/content/drive/MyDrive/{new_model_name}\"\n",
        "\n",
        "trainer.model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"✅ Model saved to Google Drive at: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T87HGE9CnAdB",
        "outputId": "17530216-230c-4b2c-c5be-d5fa88d2e7af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Model saved to Google Drive at: /content/drive/MyDrive/Mistral-7B-Medical-Finetune\n"
          ]
        }
      ]
    }
  ]
}